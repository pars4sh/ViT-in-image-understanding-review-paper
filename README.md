# üß† Vision Transformers in Image Understanding: A New Paradigm

This repository contains a comprehensive literature review on Vision Transformers (ViTs) and their role in modern image understanding tasks. The review was developed as a graduate seminar project at the **Institute of Electrical Engineering and Information Technology (IEF), University of Rostock**.

üìÑ **[Read the Full Paper (PDF)](ViT_in_image_Understanding.pdf)**

---

## ‚ú® Overview

The Vision Transformer (ViT) has emerged as a powerful alternative to convolutional neural networks (CNNs) for various computer vision tasks. This review paper explores key developments in ViT architecture, interpretability, training strategies, and real-world applications across domains like medical imaging, object detection, and video understanding.

---

## üìö Topics Covered

- **ViT Fundamentals**  
  Introduction to Transformer-based architectures in vision

- **Architectural Enhancements**  
  Hierarchical models (Swin, PVT), token reduction, hybrid CNN-Transformer designs

- **Training Strategies**  
  Self-supervised learning (MAE, DINO), transfer learning, and fine-tuning in low-data regimes

- **Interpretability and Attention Analysis**  
  Attention rollout, patch-level attention, attention distance metrics

- **Applications**  
  - Object detection (e.g., DETR, Swin Transformer)
  - Medical image classification (e.g., COVID-19 detection)
  - Video understanding (e.g., TimeSformer, Swin Video Transformer)

- **Challenges and Future Directions**  
  Computational cost, locality, inductive bias, and data efficiency

---

## üë®‚Äçüíª Authors and Contributions

| Name                            | Contribution Areas                                                                 |
|---------------------------------|-------------------------------------------------------------------------------------|
| **Erfan Yekehzare**             | Section I: Introduction, Section II: Architectural Variants, Co-author/editor     |
| **Seyyed Parsa Sharifi**        | Section V: Applications,Section VI: Challenges, Limitations, and Future Directions, Section VII: Conclusion, Abstract, Co-author/editor      |
| **Pouria Matinifard**           | Section III: Training Strategies and Data Efficiency                                |
| **Seyed Mehdi Ayati Najafabadi**| Section IV: Interpretability and Attention Analysis                                 |

*All authors are affiliated with the University of Rostock.*

---

## üß† Citation

If you use or refer to this review in your research or projects, please cite it as:

```bibtex
@misc{vit_review_2025,
  title={Vision Transformers in Image Understanding: A New Paradigm},
  author={Sharifi, Seyyed Parsa and Yekehzare, Erfan and Matinifard, Pouria and Ayati Najafabadi, Seyed Mehdi},
  year={2025},
  note={Literature review, University of Rostock},
  url={https://github.com/YOUR_USERNAME/vision-transformers-review}
}
