@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yu and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={10012--10022},
  year={2021}
}

@inproceedings{touvron2021training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2021}
}

@inproceedings{wu2021cvt,
  title={Cvt: Introducing convolutions to vision transformers},
  author={Wu, Haiping and Xiao, Bin and Codella, Noel and Liu, Mengchen and Dai, Xiaoliang and Yuan, Lu and Zhang, Lei},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={22--31},
  year={2021}
}

@inproceedings{heo2021rethinking,
  title={Rethinking spatial dimensions of vision transformers},
  author={Heo, Byeongho and Yun, Seong Joon and Han, Dongyoon and Yoo, Sangdoo and Chun, Sanghyuk},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={11936--11945},
  year={2021}
}

@article{zhang2021aggregating,
  title={Aggregating nested transformers},
  author={Zhang, Zhiheng and Luo, Yining and Yan, Hao and Zhao, Qi and Lin, Yunchao and Ma, Zhiyong and Li, Hongyang},
  journal={arXiv preprint arXiv:2105.12723},
  year={2021}
}

@inproceedings{choromanski2021rethinking,
  title={Rethinking attention with performers},
  author={Choromanski, Krzysztof and Likhosherstov, Valerii and Dohan, David and Song, Xingyou and Gane, Andreea and Sarlos, Tamas and Hawkins, Peter and Davis, Jared and Mohiuddin, Afroz and Kaiser, Lukasz and others},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@article{wang2020linformer,
  title={Linformer: Self-attention with linear complexity},
  author={Wang, Sinong and Li, Belinda Z and Khabsa, Madian and Fang, Han and Ma, Hao},
  journal={arXiv preprint arXiv:2006.04768},
  year={2020}
}

@inproceedings{yang2021focal,
  title={Focal self-attention for local-global interactions in vision transformers},
  author={Yang, Jiasen and Hou, Qibin and Zhou, Li and Cheng, Ming-Ming and Luo, Ping},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2021}
}

@inproceedings{zhu2021deformable,
  title={Deformable DETR: Deformable transformers for end-to-end object detection},
  author={Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@inproceedings{dai2021transmed,
  title={TransMed: Transformers advance multi-modal medical image classification},
  author={Dai, Ziheng and Chen, Yutong and Xu, Xinyu and Yang, Yi},
  booktitle={Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
  pages={246--256},
  year={2021}
}

@article{chen2024vitcovid,
  title={A Vision Transformer model for COVID-19 diagnosis using chest X-ray images},
  author={Chen, Qihang and Zhao, Liang and Wang, Meng and Li, Hui},
  journal={Diagnostics},
  volume={14},
  number={3},
  pages={384},
  year={2024}
}

@inproceedings{liu2022videoswin,
  title={Video Swin Transformer},
  author={Liu, Ze and Ning, Jia and Cao, Yue and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Hu, Han},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={3202--3211},
  year={2022}
}

@inproceedings{bertasius2021space,
  title={Is space-time attention all you need for video understanding?},
  author={Bertasius, Gedas and Wang, Heng and Torresani, Lorenzo},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={813--824},
  year={2021}
}

@inproceedings{feichtenhofer2019slowfast,
  title={SlowFast networks for video recognition},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Malik, Jitendra and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={6202--6211},
  year={2019}
}

@inproceedings{lin2019tsm,
  title={TSM: Temporal shift module for efficient video understanding},
  author={Lin, Ji and Gan, Chuang and Han, Song},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={7083--7093},
  year={2019}
}

@inproceedings{kwon2020motionsqueeze,
  title={MotionSqueeze: Neural motion feature learning for video understanding},
  author={Kwon, Heeseung and Kim, Manjin and Kwak, Suha and Cho, Minsu},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={345--362},
  year={2020}
}

@inproceedings{li2020tea,
  title={TEA: Temporal excitation and aggregation for action recognition},
  author={Li, Yan and Ji, Bin and Shi, Xintian and Zhang, Jianguo and Kang, Bin and Wang, Limin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={909--918},
  year={2020}
}

@article{fan2019more,
  title={More is less: Learning efficient video representations by big-little network and depthwise temporal aggregation},
  author={Fan, Quanfu and Chen, Chun-Fu and Kuehne, Hilde and Pistoia, Marco and Cox, David},
  journal={arXiv preprint arXiv:1912.00869},
  year={2019}
}

@article{arnab2021vivit,
  title={ViViT: A video vision transformer},
  author={Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lučić, Mario and Schmid, Cordelia},
  journal={arXiv preprint arXiv:2103.15691},
  year={2021}
}

@article{fan2021multiscale,
  title={Multiscale vision transformers},
  author={Fan, Haoqi and Xiong, Bo and Mangalam, Karttikeya and Li, Yanghao and Yan, Zhicheng and Malik, Jitendra and Feichtenhofer, Christoph},
  journal={arXiv preprint arXiv:2104.11227},
  year={2021}
}

@inproceedings{zhang2021attention,
  title={Visual Explanations of Vision Transformer Guided by Self-Attention},
  author={Zhang, Xiaojie and Li, Yang and Wang, Zhi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={10785--10794},
  year={2021}
}

@inproceedings{yun2022patch,
  title={Patch-level Representation Learning for Self-supervised Vision Transformers},
  author={Yun, Misun and Lee, Jaesung and Kim, Hyun},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2022}
}

@inproceedings{raghu2021vision,
  title={Do Vision Transformers See Like Convolutional Neural Networks?},
  author={Raghu, Maithra and Poole, Ben and Kleinberg, Jon and Ganguli, Surya and Sohl-Dickstein, Jascha},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={12116--12127},
  year={2021}
}

@inproceedings{caron2021emerging,
  title={Emerging Properties in Self-Supervised Vision Transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and Jégou, Hervé and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={9650--9660},
  year={2021}
}

@article{bello2020attention,
  title={Attention Augmented Convolutional Networks},
  author={Bello, Irwan and Zoph, Barret and Vaswani, Ashish and Shlens, Jonathon and Le, Quoc V},
  journal={CoRR},
  volume={abs/1904.09925},
  year={2020},
  url={https://arxiv.org/abs/1904.09925}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@inproceedings{dosovitskiy2021an,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{hu2019local,
  title={Local Relation Networks for Image Recognition},
  author={Hu, Han and Zhang, Zheng and Xie, Zhenda and Lin, Stephen},
  journal={arXiv preprint arXiv:1904.11491},
  year={2019},
  url={https://arxiv.org/abs/1904.11491}
}

@inproceedings{lin2017feature,
  title={Feature Pyramid Networks for Object Detection},
  author={Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017}
}

@inproceedings{lin2014microsoft,
  title = {Microsoft COCO: Common Objects in Context},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year = {2014},
  month = {September},
  address = {Z{\"u}rich},
  URL = {http://mscoco.org},
  author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C. Lawrence}
}

@inproceedings{radosavovic2020designing,
  author    = {Ilija Radosavovic and
               Raj Prateek Kosaraju and
               Ross B. Girshick and
               Kaiming He and
               Piotr Doll{\'{a}}r},
  title     = {Designing Network Design Spaces},
  booktitle = {{CVPR}},
  pages     = {10425--10433},
  year      = {2020}
}

@article{qiao2020detectors,
  title={Detectors: Detecting objects with recursive feature pyramid and switchable atrous convolution},
  author={Qiao, Siyuan and Chen, Liang-Chieh and Yuille, Alan},
  journal={arXiv preprint arXiv:2006.02334},
  year={2020},
  url={https://arxiv.org/abs/2006.02334}
}

@inproceedings{ramachandran2019stand,
  title={Stand-Alone Self-Attention in Vision Models},
  author={Ramachandran, Prajit and Parmar, Niki and Vaswani, Ashish and Bello, Irwan and Levskaya, Anselm and Shlens, Jon},
  booktitle={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{kay2017kinetics,
  title={The Kinetics Human Action Video Dataset},
  author={Kay, Will and Carreira, Joao and Simonyan, Karen and others},
  booktitle={arXiv preprint arXiv:1705.06950},
  year={2017}
}

@inproceedings{ronneberger2015u,
  author = "Ronneberger, O. and Fischer, P. and Brox, T.",
  title = "U-Net: Convolutional Networks for Biomedical Image Segmentation",
  booktitle = "Medical Image Computing and Computer-Assisted Intervention (MICCAI)",
  series = "LNCS",
  volume = "9351",
  pages = "234--241",
  year = "2015",
  publisher = "Springer",
  note = "(available on arXiv:1505.04597 [cs.CV])",
  url = "https://lmb.informatik.uni-freiburg.de/Publications/2015/RFB15a/"
}

@inproceedings{singh2018analysis,
  title={An Analysis of Scale Invariance in Object Detection - SNIP},
  author={Singh, Bharat and Davis, Larry S},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018},
  url={https://arxiv.org/abs/1711.08189}
}

@inproceedings{singh2018sniper,
  title={SNIPER: Efficient Multi-Scale Training},
  author={Singh, Bharat and Najibi, Mahyar and Davis, Larry S},
  booktitle={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{tan2019efficientnet,
  title={EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
  author={Tan, Mingxing and Le, Quoc V},
  booktitle={International Conference on Machine Learning},
  pages={6105--6114},
  year={2019},
  organization={PMLR}
}

@inproceedings{vaswani2017attention,
  title={Attention is All you Need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017},
  pages={5998--6008}
}

@misc{cai2022efficientvit,
  author       = {Han Cai and Ji Lin and Mingyu Hu and Chuang Gan and Song Han},
  title        = {EfficientViT: Multi-scale Linear Attention for High-Resolution Dense Prediction},
  year         = {2022},
  howpublished = {\url{https://api.semanticscholar.org/CorpusID:262824134}},
  note         = {Online; accessed 2025-06-04}
}

@inproceedings{li2022mvitv2,
  author    = {Y. Li and C. Wu and H. Fan and K. Mangalam and B. Xiong and J. Malik and C. Feichtenhofer},
  title     = {MViTv2: Improved Multiscale Vision Transformers for Classification and Detection},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2022},
  pages     = {4794--4804}
}

@inproceedings{goyal2017something,
  author    = {Raghav Goyal and Samira Ebrahimi Kahou and Vincent Michalski and Joanna Materzynska and Susanne Westphal and Heuna Kim and Valentin Haenel and Ingo Fründ and Peter Yianilos and Moritz Mueller-Freitag and Florian Hoppe and Christian Thurau and Ingo Bax and Roland Memisevic},
  title     = {The "Something Something" Video Database for Learning and Evaluating Visual Common Sense},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  year      = {2017},
  pages     = {5842--5850},
  doi       = {10.1109/ICCV.2017.622},
  url       = {https://openaccess.thecvf.com/content_ICCV_2017/papers/Goyal_The_Something_Something_ICCV_2017_paper.pdf}
}

@article{zhai2022scaling,
  title={Scaling Vision Transformers},
  author={Zhai, Xiaohua and Hassani, Ali and Mustikovela, Sjoerd and Kolesnikov, Alexander and Houlsby, Neil and Beyer, Lucas},
  journal={CVPR},
  year={2022},
  url={https://arxiv.org/abs/2111.09883}
}

@article{he2022masked,
  title={Masked Autoencoders Are Scalable Vision Learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  journal={CVPR},
  year={2022},
  pages={16000--16009},
  url={https://arxiv.org/abs/2111.06377}
}

@article{chen2021empirical,
  title={An Empirical Study of Training Self-Supervised Vision Transformers},
  author={Chen, Xinlei and Xie, Saining and He, Kaiming},
  journal={ICCV},
  year={2021},
  url={https://arxiv.org/abs/2104.02057}
}

@inproceedings{Simonyan2015very,
  author={Karen Simonyan and Andrew Zisserman},
  editor={Yoshua Bengio and Yann LeCun},
  title={Very Deep Convolutional Networks for Large-Scale Image Recognition},
  booktitle={International Conference on Learning Representations},
  year={2015}
}

@inproceedings{Lin2017focal,
  author={Tsung-Yi Lin and Priya Goyal and Ross Girshick and Kaiming He and Piotr Doll{\'a}r},
  title={Focal Loss for Dense Object Detection},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  year={2017}
}

@inproceedings{He2017mask,
  author={Kaiming He and Georgia Gkioxari and Piotr Doll{\'a}r and Ross Girshick},
  title={Mask R-CNN},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  year={2017}
}

@inproceedings{He2016deep,
  author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  title={Deep Residual Learning for Image Recognition},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year={2016}
}

@inproceedings{Carion2020endtoend,
  author={Nicolas Carion and Francisco Massa and Gabriel Synnaeve and Nicolas Usunier and Alexander Kirillov and Sergey Zagoruyko},
  title={End-to-End Object Detection with Transformers},
  booktitle={Proceedings of the European Conference on Computer Vision},
  year={2020}
}

@misc{wang2021pyramidvisiontransformerversatile, 
  title={Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions},
  author={Wenhai Wang and Enze Xie and Xiang Li and Deng-Ping Fan and Kaitao Song and Ding Liang and Tong Lu and Ping Luo and Ling Shao},
  year={2021}, 
  eprint={2102.12122},
  archivePrefix={arXiv},
  primaryClass={cs.CV}, 
  url={https://arxiv.org/abs/2102.12122},
}

@article{ruan2022vision,
  title={Vision Transformers: State of the Art and Research Challenges},
  author={Ruan, Yongqiang and Li, Yixuan and Zhou, Pan and Wang, Jiang and Zhao, Xiangyu and Wang, Xinlong and Xie, Enze and Li, Zechun and Luo, Ping},
  journal={arXiv preprint arXiv:2207.03041},
  year={2022}
}

@article{elharrouss2024transformer,
  title={Transformer-based Image and Video Inpainting: Current Challenges and Future Directions},
  author={Elharrouss, Omar and Hamed, Ahmed and Al-Maadeed, Somaya and Elbouz, Marouane},
  journal={Artificial Intelligence Review},
  year={2024},
  publisher={Springer},
  doi={10.1007/s10462-024-11075-9}
}

@misc{xie2017aggregatedresidualtransformationsdeep,
      title={Aggregated Residual Transformations for Deep Neural Networks}, 
      author={Saining Xie and Ross Girshick and Piotr Dollár and Zhuowen Tu and Kaiming He},
      year={2017},
      eprint={1611.05431},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1611.05431}, 
}